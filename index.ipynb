{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "enormous-auckland",
   "metadata": {},
   "source": [
    "# Cross Validation Code Along"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dietary-shoot",
   "metadata": {},
   "outputs": [],
   "source": [
    "from seaborn import get_dataset_names, load_dataset\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breathing-equality",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run without changes\n",
    "diamonds = load_dataset('diamonds')\n",
    "diamonds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disciplinary-criterion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run without changes\n",
    "from seaborn import get_dataset_names, load_dataset\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "diamonds = load_dataset('diamonds')\n",
    "\n",
    "# 21551 diamonds are ideal, so almost half of the 53939\n",
    "# We will change this into an ideal/not ideal binary problem\n",
    "\n",
    "def make_ideal_not_ideal(element):\n",
    "    if element == \"Ideal\":\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "diamonds['cut'] = diamonds['cut'].apply(make_ideal_not_ideal)\n",
    "diamonds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungry-class",
   "metadata": {},
   "outputs": [],
   "source": [
    "diamonds['cut'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forbidden-gardening",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floral-vehicle",
   "metadata": {},
   "source": [
    "We have a healthy dataset here, as far as records go.  There are almost 54,000 records."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "russian-metadata",
   "metadata": {},
   "source": [
    "In the cell below, split the data with a test size of 20%.   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "superior-guitar",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "descending-click",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "located-jewel",
   "metadata": {},
   "source": [
    "Now that we have split off the test set, we can experiment with the train set. We will use cross-validation to shuffle the training data, as shown in the diagram below.\n",
    "\n",
    "![cross_val](images/grid_search_cross_validation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unnecessary-health",
   "metadata": {},
   "source": [
    "Let's build a **First Simple Model** using a `DummyClassifier.`  \n",
    "\n",
    "The DummyClassifier takes an argument `strategy`, which dictates what type of predictions it makes.  Set `strategy` equal to `most_frequent`. Based on our knowledge of the class balance, the DummyClassifer should always predict `0`, i.e. `not_ideal`.\n",
    "\n",
    "Put the dummy classifier into a `cross_validate` function, and calculate the mean test scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polar-assault",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acknowledged-japan",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "technological-modification",
   "metadata": {},
   "source": [
    "You should have returned a mean test score of .60.  What does that .60 represent?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forced-roman",
   "metadata": {},
   "source": [
    "#your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "american-avenue",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sticky-transportation",
   "metadata": {},
   "source": [
    "Instantiate a logistic regression classifier with the default parameters plus `random_state=42`.  Feed that into the `cross_validate` function. Make sure to set `return_train_score=True`.  Print out the mean train and test scores.\n",
    "\n",
    "**hint** Logistic Regression will break with categoricals.  Feed in only continuous variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worse-million",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advance-kidney",
   "metadata": {},
   "source": [
    "Answer the following questions about the above results:\n",
    "\n",
    "Does logistic regression perform better than the dummy classifier?\n",
    "\n",
    "Is the model high or low bias? What about high or low variance?  \n",
    "Is the model over or under fit? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "behind-geology",
   "metadata": {},
   "source": [
    "Use the `cross_val_predict` function from sklearn to investigate the actual predictions across the different folds:  [cross_val_predict](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_predict.html)\n",
    "\n",
    "Put those predictions into a confusion matrix using sklearn's. `confusion_matrix` method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entertaining-characterization",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caroline-fleet",
   "metadata": {},
   "source": [
    "# Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alone-corpus",
   "metadata": {},
   "source": [
    "Remember that scaling is important when regularization is being peformed. If you look at the Logistic Regression docstring, you will see that `l2` regularization is being performed by default.  Let's see the effect scaling the data has on the scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bound-smith",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate a standard scalar, scale the data and feed it into cross_validate\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# print out mean train and test scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "periodic-framework",
   "metadata": {},
   "source": [
    "Describe where data leakage occured in the above piece of code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceramic-doctor",
   "metadata": {},
   "source": [
    "To ensure there is no leakage, we will implement KFold cross_validation.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complete-somalia",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold()\n",
    "\n",
    "train_score = []\n",
    "vald_score = []\n",
    "\n",
    "for train_ind, val_ind in kf.split(X_train_continuous, y_train):\n",
    "    # use train_ind and iloc to isolate the training records associated with each fold\n",
    "    \n",
    "    # use val_ind to isolate validation records\n",
    "    \n",
    "    # instantiate a scalar and fit it on the train. \n",
    "    \n",
    "    # transform the train and val records with the scalar\n",
    "    \n",
    "    # instantiate a logistic regression model\n",
    "    \n",
    "    # fit logistic regression on train set.\n",
    "    \n",
    "    # score on both train and val and append to train/val_score lists\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wired-district",
   "metadata": {},
   "source": [
    "The above code is hard! KFolds helps us understand what is happening under the hood.  When we get to pipelines, however, much of this can be done in a few lines of code. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
